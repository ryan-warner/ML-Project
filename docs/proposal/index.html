<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="description" content="Astro description"><meta name="viewport" content="width=device-width"><link rel="icon" type="image/svg+xml" href="./favicon.svg"><meta name="generator" content="Astro v4.4.0"><title>ML Project</title><style>*,:before,:after{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e5e7eb}:before,:after{--tw-content: ""}html,:host{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;-o-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,sans-serif,"Apple Color Emoji","Segoe UI Emoji",Segoe UI Symbol,"Noto Color Emoji";font-feature-settings:normal;font-variation-settings:normal;-webkit-tap-highlight-color:transparent}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}abbr:where([title]){-webkit-text-decoration:underline dotted;text-decoration:underline dotted}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}b,strong{font-weight:bolder}code,kbd,samp,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-feature-settings:normal;font-variation-settings:normal;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}table{text-indent:0;border-color:inherit;border-collapse:collapse}button,input,optgroup,select,textarea{font-family:inherit;font-feature-settings:inherit;font-variation-settings:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0;padding:0}button,select{text-transform:none}button,[type=button],[type=reset],[type=submit]{-webkit-appearance:button;background-color:transparent;background-image:none}:-moz-focusring{outline:auto}:-moz-ui-invalid{box-shadow:none}progress{vertical-align:baseline}::-webkit-inner-spin-button,::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}summary{display:list-item}blockquote,dl,dd,h1,h2,h3,h4,h5,h6,hr,figure,p,pre{margin:0}fieldset{margin:0;padding:0}legend{padding:0}ol,ul,menu{list-style:none;margin:0;padding:0}dialog{padding:0}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{opacity:1;color:#9ca3af}input::placeholder,textarea::placeholder{opacity:1;color:#9ca3af}button,[role=button]{cursor:pointer}:disabled{cursor:default}img,svg,video,canvas,audio,iframe,embed,object{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}[hidden]{display:none}*,:before,:after{--tw-border-spacing-x: 0;--tw-border-spacing-y: 0;--tw-translate-x: 0;--tw-translate-y: 0;--tw-rotate: 0;--tw-skew-x: 0;--tw-skew-y: 0;--tw-scale-x: 1;--tw-scale-y: 1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness: proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width: 0px;--tw-ring-offset-color: #fff;--tw-ring-color: rgb(59 130 246 / .5);--tw-ring-offset-shadow: 0 0 #0000;--tw-ring-shadow: 0 0 #0000;--tw-shadow: 0 0 #0000;--tw-shadow-colored: 0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }::backdrop{--tw-border-spacing-x: 0;--tw-border-spacing-y: 0;--tw-translate-x: 0;--tw-translate-y: 0;--tw-rotate: 0;--tw-skew-x: 0;--tw-skew-y: 0;--tw-scale-x: 1;--tw-scale-y: 1;--tw-pan-x: ;--tw-pan-y: ;--tw-pinch-zoom: ;--tw-scroll-snap-strictness: proximity;--tw-gradient-from-position: ;--tw-gradient-via-position: ;--tw-gradient-to-position: ;--tw-ordinal: ;--tw-slashed-zero: ;--tw-numeric-figure: ;--tw-numeric-spacing: ;--tw-numeric-fraction: ;--tw-ring-inset: ;--tw-ring-offset-width: 0px;--tw-ring-offset-color: #fff;--tw-ring-color: rgb(59 130 246 / .5);--tw-ring-offset-shadow: 0 0 #0000;--tw-ring-shadow: 0 0 #0000;--tw-shadow: 0 0 #0000;--tw-shadow-colored: 0 0 #0000;--tw-blur: ;--tw-brightness: ;--tw-contrast: ;--tw-grayscale: ;--tw-hue-rotate: ;--tw-invert: ;--tw-saturate: ;--tw-sepia: ;--tw-drop-shadow: ;--tw-backdrop-blur: ;--tw-backdrop-brightness: ;--tw-backdrop-contrast: ;--tw-backdrop-grayscale: ;--tw-backdrop-hue-rotate: ;--tw-backdrop-invert: ;--tw-backdrop-opacity: ;--tw-backdrop-saturate: ;--tw-backdrop-sepia: }.flex{display:flex}.h-24{height:6rem}.h-4\/5{height:80%}.h-48{height:12rem}.h-\[60vh\]{height:60vh}.h-\[66vh\]{height:66vh}.h-full{height:100%}.w-72{width:18rem}.w-\[45\%\]{width:45%}.w-full{width:100%}.w-min{width:-moz-min-content;width:min-content}.flex-1{flex:1 1 0%}.list-disc{list-style-type:disc}.flex-col{flex-direction:column}.items-center{align-items:center}.justify-center{justify-content:center}.justify-between{justify-content:space-between}.gap-12{gap:3rem}.gap-2{gap:.5rem}.gap-24{gap:6rem}.gap-4{gap:1rem}.gap-8{gap:2rem}.divide-y-4>:not([hidden])~:not([hidden]){--tw-divide-y-reverse: 0;border-top-width:calc(4px * calc(1 - var(--tw-divide-y-reverse)));border-bottom-width:calc(4px * var(--tw-divide-y-reverse))}.self-center{align-self:center}.overflow-hidden{overflow:hidden}.rounded-2xl{border-radius:1rem}.bg-light-primary{--tw-bg-opacity: 1;background-color:rgb(245 245 245 / var(--tw-bg-opacity))}.bg-gradient-to-r{background-image:linear-gradient(to right,var(--tw-gradient-stops))}.from-indigo-500{--tw-gradient-from: #6366f1 var(--tw-gradient-from-position);--tw-gradient-to: rgb(99 102 241 / 0) var(--tw-gradient-to-position);--tw-gradient-stops: var(--tw-gradient-from), var(--tw-gradient-to)}.via-sky-500{--tw-gradient-to: rgb(14 165 233 / 0) var(--tw-gradient-to-position);--tw-gradient-stops: var(--tw-gradient-from), #0ea5e9 var(--tw-gradient-via-position), var(--tw-gradient-to)}.to-emerald-500{--tw-gradient-to: #10b981 var(--tw-gradient-to-position)}.bg-clip-text{-webkit-background-clip:text;background-clip:text}.object-contain{-o-object-fit:contain;object-fit:contain}.object-cover{-o-object-fit:cover;object-fit:cover}.px-12{padding-left:3rem;padding-right:3rem}.px-16{padding-left:4rem;padding-right:4rem}.px-8{padding-left:2rem;padding-right:2rem}.px-\[15\%\]{padding-left:15%;padding-right:15%}.py-6{padding-top:1.5rem;padding-bottom:1.5rem}.pt-24{padding-top:6rem}.text-2xl{font-size:1.5rem;line-height:2rem}.text-4xl{font-size:2.25rem;line-height:2.5rem}.text-6xl{font-size:3.75rem;line-height:1}.text-8xl{font-size:6rem;line-height:1}.font-bold{font-weight:700}.font-semibold{font-weight:600}.text-black{--tw-text-opacity: 1;color:rgb(0 0 0 / var(--tw-text-opacity))}.text-transparent{color:transparent}.text-white{--tw-text-opacity: 1;color:rgb(255 255 255 / var(--tw-text-opacity))}.ring{--tw-ring-offset-shadow: var(--tw-ring-inset) 0 0 0 var(--tw-ring-offset-width) var(--tw-ring-offset-color);--tw-ring-shadow: var(--tw-ring-inset) 0 0 0 calc(3px + var(--tw-ring-offset-width)) var(--tw-ring-color);box-shadow:var(--tw-ring-offset-shadow),var(--tw-ring-shadow),var(--tw-shadow, 0 0 #0000)}.hover\:underline:hover{text-decoration-line:underline}.hover\:opacity-80:hover{opacity:.8}
</style></head> <body class="bg-light-primary"> <div class="h-18 w-full flex justify-between py-6 px-12"> <div class="text-black flex items-center justify-center"> <a href="./" class="text-4xl font-bold">CS 4641 Project</a> </div> <div class="flex gap-4"> <a href="./proposal" class="flex flex-col justify-center"> <div class="text-black text-2xl hover:opacity-80">Project Proposal</div> </a> <a href="./contributors/" class="flex flex-col justify-center"> <div class="text-black text-2xl hover:opacity-80">Contributors</div> </a> </div> </div>  <div class="flex flex-col gap-12"> <div class="h-[60vh] w-full flex flex-col justify-center bg-gradient-to-r from-indigo-500 via-sky-500 to-emerald-500"> <div class="text-white text-8xl font-semibold px-[15%]">Project Proposal</div> </div> <div class=" px-[15%] flex flex-col gap-8"> <div class="flex flex-col gap-4 divide-y-4"> <div class="text-6xl font-semibold">Introduction and Background</div> <div class="flex flex-col gap-4"> <div class="text-2xl">
The objective of our project is to distinguish between human and AI photography.
</div> <div class="text-2xl">
Modern research on the topic is extensive. Many are concerned about the dangers of deepfaked images and counterfeit art. Baraheem [1] discusses whether AIs themselves can truly make this distinction, although they claim a suspiciously high 100% accuracy on their dataset. Epstein [2] presents a similar discussion, highlighting the challenges associated with this sort of classification with AI's rapid development, extending their analysis to a simulated release cadence. Göring et. al [3] present a more qualitative, high-level approach, exploring the appeal of AI images to begin with.
</div> <div class="text-2xl">
The dataset we have chosen is the <a class="font-bold hover:underline" href="https://genimage-dataset.github.io/" target="_blank">GenImage dataset [4]</a>, created by researchers in Huawei's Noah's Ark Lab. It contains ~1M real and generated image pairs produced by a variety of AI models. It uses the same classes as ImageNet, one of the most widely used datasets in CV research.
</div> </div> </div> <div class="flex flex-col gap-4 divide-y-4"> <div class="text-6xl font-semibold">Problem Definition</div> <div class="flex flex-col gap-4"> <div class="text-2xl">
</div> <div class="text-2xl ">
We are approaching a point where AI and human content are indistinguishable. In photography, this is particularly concerning. We believe photos capture human experiences and are worth preserving. The goal of this project is not to inhibit or criticize the potential of AI tools but to ensure that the human experience is not lost.
</div> </div> </div> <div class="flex flex-col gap-4 divide-y-4"> <div class="text-6xl font-semibold">Methods</div> <div class="flex flex-col gap-4"> <div class="flex flex-col gap-2"> <div class="text-4xl font-semibold">Preprocessing</div> <div class="text-2xl">
Considering GPU limitations and the nature of processsing images, the team  will perform transformations to decrease time complexity and look into on-campus computing facilities. The following methods, typical of image classification research, have been chosen because they offer the following benefits:
<ul class="list-disc px-8"> <li><strong>Greyscale Conversion</strong> reduces dataset dimensionality, decreasing computational cost.</li> <li><strong>Image Standardization</strong> scales pixel values of an image, ensuring that the model is not biased towards one pixel value.</li> <li><strong>Image Augmentation</strong> artificially increases the size of the dataset by randomly transforming images, allowing the model to learn from a wider variety of images without a larger dataset.</li> </ul> </div> </div> <div class="flex flex-col gap-2"> <div class="text-4xl font-semibold">Modeling: </div> <div class="text-2xl">
The team must select a GAN architecture. The following models are potential candidates for classification:
<ul class="list-disc px-8"> <li><strong>Convolutional Neural Networks</strong> are widely used in image classification, which may prove helpful if AI generators leave unique artifacts.</li> <li><strong>Support Vector Machines</strong> are another candidate, good at working with high-dimensional data and are less prone to overfitting, helpful for truly generalizing our model.</li> <li><strong>Generative Adversarial Networks</strong> may also be another option and might not require an AI generated dataset, as the discriminator in a GAN is trained to distinguish between the input and generated dataset.</li> </ul></div> </div> </div> </div> <div class="flex flex-col gap-4 divide-y-4"> <div class="text-6xl font-semibold">Results and Discussion</div> <div class="text-2xl">
For this project, we hope to achieve an <strong>accuracy</strong> of at least 90%. Accuracy is a good general metric to quantify model performance. Project success is additionally quantified by a <strong>ROC AUC</strong> score of at least 0.8, generally considered acceptable, and quantifies the model's ability to distinguish between the two classes. Lastly, we'll consider <strong>recall</strong>, with success marked by a score of at least 0.8, as we generally care that the model is able to correctly identify AI generated images (true positive), but a little less if it mislabels a human generated image as AI (false negative).
</div> </div> <div class="flex flex-col gap-4 divide-y-4"> <div class="text-6xl font-semibold">References</div> <div class="text-2xl flex flex-col gap-2"> 
  <div data-csl-entry-id="jimaging9100199" class="csl-entry">Baraheem, S. S., &#38; Nguyen, T. V. (2023). AI vs. AI: Can AI Detect AI-Generated Images? <i>Journal of Imaging</i>, <i>9</i>(10), 199. https://doi.org/10.3390/jimaging9100199</div>
  <div data-csl-entry-id="Epstein_2023_ICCV" class="csl-entry">Epstein, D. C., Jain, I., Wang, O., &#38; Zhang, R. (2023). Online Detection of AI-Generated Images. <i>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops</i>, 382–392.</div>
  <div data-csl-entry-id="10103686" class="csl-entry">Göring, S., Ramachandra Rao, R. R., Merten, R., &#38; Raake, A. (2023). Analysis of Appeal for Realistic AI-Generated Photos. <i>IEEE Access</i>, <i>11</i>, 38999–39012. https://doi.org/10.1109/ACCESS.2023.3267968</div>
  <div data-csl-entry-id="lu2023seeing" class="csl-entry">Lu, Z., Huang, D., Bai, L., Qu, J., Wu, C., Liu, X., &#38; Ouyang, W. (2023). <i>Seeing is not always believing: Benchmarking Human and Model Perception of AI-Generated Images</i>. arXiv.</div>
  <div data-csl-entry-id="zhu2023genimage" class="csl-entry">Zhu, M., Chen, H., Yan, Q., Huang, X., Lin, G., Li, W., Tu, Z., Hu, H., Hu, J., &#38; Wang, Y. (2023). <i>GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image</i>. arXiv.</div>
 </div> </div> </div> </div> <div class="w-full h-48 flex justify-center items-center pt-24"> <div class="font-semibold text-2xl"> Made with ❤ in Atlanta, GA </div> </div> </body></html>