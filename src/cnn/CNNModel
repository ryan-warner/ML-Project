import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Conv2D, MaxPool2D, Flatten, Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split #new

#trying to use our dataset
from dataset.fake_dataset import FakeDataset
from dataset.real_dataset import RealDataset
import sys

# these imports + loading is for mnist dataset
import gzip
import sys
import pickle

f = gzip.open('mnist.pkl.gz', 'rb')
if (sys.version_info < (3,)):
    data = pickle.load(f)
else:
    data = pickle.load(f, encoding='bytes')
f.close()
# def dataset():
(X_train, y_train), (X_test, y_test) = data # load data, used with the mnist dataset

# reshape data
X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)) # used with the mnist dataset
X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)) # used with the mnist dataset

# check the shape
print("X_train shape:", X_train.shape) # used with the mnist dataset
print("y_train shape:", y_train.shape) # used with the mnist dataset
print("X_test shape:", X_test.shape) # used with the mnist dataset
print("y_test shape:", y_test.shape) # used with the mnist dataset

# normalize pixel values
X_train = X_train / 255 # used with the mnist dataset
X_test = X_test / 255 # used with the mnist dataset

# def model():
model = Sequential() # define/init model
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # add 1 convolution layer
model.add(MaxPool2D(2, 2)) # add pooling layer

# add 2nd convolution layer
# model.add(Conv2D(32, 3, 3, activation='relu')) # used w/ cats & dogs dataset
# model.add(MaxPool2D(pool_size=(2,2))) # used w/ cats & dogs dataset
model.add(Flatten()) # flattening

# full connection
model.add(Dense(100, activation='relu')) # hidden layer, change accordingly (for dataset)
model.add(Dense(10, activation='softmax')) # output layer, change accordingly (for dataset)
model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # compile model, change loss according to dataset

model.fit(X_train, y_train, epochs=3) # fit model
model.evaluate(X_test, y_test)

# for cats & dogs vvv
# train_datagen = ImageDataGenerator(
#     rescale=1./255,
#     shear_range=0.2,
#     zoom_range=0.2,
#     horizontal_flip=True
# )
# test_datagen = ImageDataGenerator(rescale=1./255)
# train_set = train_datagen.flow_from_directory('dataset/training_set',
#                                                 target_size=(64, 64),
#                                                 batch_size=32,
#                                                 class_mode='binary')
# test_set = test_datagen.flow_from_directory('dataset/test_set',
#                                             target_size=(64, 64),
#                                             batch_size=32,
#                                             class_mode='binary')
# model.fit(train_set,
#           epochs=1,
#           steps_per_epoch=8000)

